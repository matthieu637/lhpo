[simulation]
#the total number of learning episode
max_episode=30

#the number of test episode at each end of a learning episode
test_episode_per_episode=0

#the total number of testing episode after the learning phase
test_episode_at_end=0
#if you want to test the performance of the agent
#max_episode=0

#dump to file each n episode
dump_log_each=1

#display to standard output each n episode
display_log_each=1000

#save the agent each n episode
save_agent_each=50000

#the total number of learning episode


[environment]
#during one episode, the simulator can iterate over multiple instance
#for instance with a stochastic environment
instance_per_episode=1

#to limit the number of step for one instance
max_step_per_instance=500
apply_armature=true
damping=0
approx=1
mu=0.8
mu2=-1
soft_cfm=0.02
slip1=-1
slip2=-1
soft_erp=-1
bounce=-1
control=2
reward=3

[agent]
decision_each=1
gamma=0.99

hidden_unit_a=5:5:2
population=50
gaussian_policy=true
policy_stochasticity=0.05

actor_hidden_layer_type=1
actor_output_layer_type=0
batch_norm=0
initial_deviation=0.2

[devnn]
st_scale=false
ac_scale=false
st_probabilistic=1
ac_probabilistic=1
st_control=4:5:7:8:13:14:16:17
ac_control=1:2:4:5
heuristic=1
heuristic_devpoints=1000,1000,1000,1000,1000,1000,1000,1000
heuristic_linearcoef=0.0005:0.0005:0.0005:0.0005:0.0005:0.0005
compute_diff_backward=false
reset_learning_algo=false

